# correct_results_parser.py
import requests
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
from database import get_db_connection
import time

def parse_results_html(date_str):
    """
    –ü–∞—Ä—Å–∏—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –º–∞—Ç—á–µ–π –∑–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –¥–∞—Ç—É –∏–∑ HTML —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
    """
    url = f"https://scores24.live/ru/soccer/{date_str}"
    print(f"üï∏Ô∏è  –ü–∞—Ä—Å–∏–º URL: {url}")
    
    try:
        response = requests.get(url, headers={
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        response.raise_for_status()
    except requests.RequestException as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ: {e}")
        return []
    
    soup = BeautifulSoup(response.text, 'html.parser')
    results = []
    
    # –ò—â–µ–º –≤—Å–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã —Å –º–∞—Ç—á–∞–º–∏ - –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã
    match_containers = soup.find_all('div', class_='sc-5a92rz-13')  # –û—Å–Ω–æ–≤–Ω–æ–π –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –º–∞—Ç—á–∞
    
    print(f"üîç –ù–∞–π–¥–µ–Ω–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤ –º–∞—Ç—á–µ–π: {len(match_containers)}")
    
    for container in match_containers:
        try:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—Å—ã–ª–∫—É —Å –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏ –∫–æ–º–∞–Ω–¥
            link_elem = container.find('a', class_='link')
            if not link_elem:
                continue
                
            # –ò–∑ href –º–æ–∂–Ω–æ –∏–∑–≤–ª–µ—á—å –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–º–∞–Ω–¥
            href = link_elem.get('href', '')
            if 'west-ham-united-chelsea' in href:
                home_team = '–í–µ—Å—Ç –•—ç–º'
                away_team = '–ß–µ–ª—Å–∏'
            else:
                # –ü—Ä–æ–±—É–µ–º –∏–∑–≤–ª–µ—á—å –∏–∑ —Ç–µ–∫—Å—Ç–∞ —Å—Å—ã–ª–∫–∏ –∏–ª–∏ –¥—Ä—É–≥–∏—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
                teams_text = link_elem.get_text(strip=True)
                if teams_text and ' - ' in teams_text:
                    home_team, away_team = teams_text.split(' - ', 1)
                else:
                    continue
            
            # –ò—â–µ–º —Å—á–µ—Ç - –∏—â–µ–º —ç–ª–µ–º–µ–Ω—Ç —Å –∫–ª–∞—Å—Å–æ–º –¥–ª—è —Å—á–µ—Ç–∞
            score_elem = container.find('div', class_='sc-17qxh4e-10')  # –í–æ–∑–º–æ–∂–Ω—ã–π –∫–ª–∞—Å—Å –¥–ª—è —Å—á–µ—Ç–∞
            if not score_elem:
                score_elem = container.find('span', class_='score')
                
            score_text = score_elem.get_text(strip=True) if score_elem else '?-?'
            
            # –ü–∞—Ä—Å–∏–º —Å—á–µ—Ç
            home_score = None
            away_score = None
            if ':' in score_text:
                try:
                    home_score, away_score = map(int, score_text.split(':'))
                except ValueError:
                    pass
            
            # –ò—â–µ–º —Å—Ç–∞—Ç—É—Å –º–∞—Ç—á–∞
            status_elem = container.find('div', class_='status')
            status = status_elem.get_text(strip=True) if status_elem else '–ó–∞–≤–µ—Ä—à–µ–Ω'
            
            result = {
                'home_team': home_team.strip(),
                'away_team': away_team.strip(),
                'home_score': home_score,
                'away_score': away_score,
                'score': score_text,
                'status': status,
                'source': 'html'
            }
            
            results.append(result)
            print(f"   ‚öΩ {home_team} {score_text} {away_team}")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ –º–∞—Ç—á–∞: {e}")
            continue
    
    return results

def debug_page_structure(date_str):
    """
    –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ - —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤—Å—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    """
    url = f"https://scores24.live/ru/soccer/{date_str}"
    response = requests.get(url, headers={
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    })
    
    soup = BeautifulSoup(response.text, 'html.parser')
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–Ω—ã–π HTML
    with open(f"debug_full_{date_str}.html", "w", encoding="utf-8") as f:
        f.write(soup.prettify())
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ –∫–ª–∞—Å—Å—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    all_classes = set()
    for element in soup.find_all(class_=True):
        all_classes.update(element.get('class', []))
    
    with open(f"debug_classes_{date_str}.txt", "w", encoding="utf-8") as f:
        for cls in sorted(all_classes):
            f.write(f"{cls}\n")
    
    print(f"‚úÖ Debug files saved: debug_full_{date_str}.html and debug_classes_{date_str}.txt")

def get_matches_without_results():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –º–∞—Ç—á–µ–π –∏–∑ predictions –±–µ–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ results."""
    conn = get_db_connection()
    cur = conn.cursor()
    
    query = """
        SELECT p.id, p.home_team, p.away_team, p.match_time
        FROM predictions p
        WHERE NOT EXISTS (
            SELECT 1 
            FROM results r 
            WHERE r.home_team = p.home_team 
            AND r.away_team = p.away_team 
            AND r.match_time = p.match_time
        )
        ORDER BY p.match_time DESC;
    """
    
    cur.execute(query)
    matches = cur.fetchall()
    cur.close()
    conn.close()
    return matches

def save_result_to_db(home_team, away_team, match_time, home_score, away_score, status):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –º–∞—Ç—á–∞ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö."""
    conn = get_db_connection()
    cur = conn.cursor()
    
    try:
        cur.execute("""
            INSERT INTO results (home_team, away_team, match_time, home_score, away_score, status, updated_at)
            VALUES (%s, %s, %s, %s, %s, %s, NOW())
        """, (home_team, away_team, match_time, home_score, away_score, status))
        
        conn.commit()
        print(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {home_team} {home_score}:{away_score} {away_team}")
        return True
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏: {e}")
        conn.rollback()
        return False
    
    finally:
        cur.close()
        conn.close()

def main():
    print("üîç –ü–ê–†–°–ï–† –†–ï–ó–£–õ–¨–¢–ê–¢–û–í (HTML —Å—Ç—Ä—É–∫—Ç—É—Ä–∞)")
    print("=" * 60)
    
    # –°–Ω–∞—á–∞–ª–∞ —Å–¥–µ–ª–∞–µ–º debug —á—Ç–æ–±—ã –ø–æ–Ω—è—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É
    print("üìã –î–µ–±–∞–≥–∏–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Å—Ç—Ä–∞–Ω–∏—Ü—ã...")
    debug_page_structure("2025-08-23")
    
    # –ó–∞—Ç–µ–º –ø–∞—Ä—Å–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print("\nüìÖ –ü–∞—Ä—Å–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã...")
    results = parse_results_html("2025-08-23")
    print(f"üìä –ù–∞–π–¥–µ–Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {len(results)}")
    
    # –ü–æ–ª—É—á–∞–µ–º –º–∞—Ç—á–∏ –∏–∑ –ë–î
    print("\nüì¶ –ó–∞–≥—Ä—É–∂–∞–µ–º –º–∞—Ç—á–∏ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö...")
    matches = get_matches_without_results()
    print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ –º–∞—Ç—á–µ–π –±–µ–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {len(matches)}")
    
    # –°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    saved_count = 0
    for match in matches:
        match_id, home_team, away_team, match_time = match
        print(f"\nüîç –ò—â–µ–º: {home_team} vs {away_team}")
        
        for result in results:
            if (result['home_team'].lower() == home_team.lower() and 
                result['away_team'].lower() == away_team.lower()):
                
                print(f"   ‚úÖ –ù–∞–π–¥–µ–Ω —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {result['home_score']}:{result['away_score']}")
                
                if save_result_to_db(
                    home_team, away_team, match_time,
                    result['home_score'], result['away_score'],
                    result['status']
                ):
                    saved_count += 1
                break
        else:
            print(f"   ‚ùå –†–µ–∑—É–ª—å—Ç–∞—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω")
    
    print(f"\nüéØ –ò–¢–û–ì: —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ {saved_count} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")

if __name__ == '__main__':
    main()
